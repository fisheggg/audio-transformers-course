# 实战练习

现在轮到你来上手练习了！本课一共包含了四个实战练习，完成这些练习后，你就可以获得课程结业证书了。

下面是本次实战练习的介绍：
本单元中，我们演示了如何在 `marsyas/gtzan` 数据集上对 Hubert 模型进行微调，并进行音乐分类任务。我们的示例实现了 83% 的准确率。
你的任务是进一步提高模型的准确率指标。

你可以在[🤗 Hub](https://huggingface.co/models)上选择任何你认为适合音频分类的模型，然后使用相同的数据集 [`marsyas/gtzan`](https://huggingface.co/datasets/marsyas/gtzan) 来构建自己的分类器。

你的目标是在这个数据集上实现 87% 的准确率。你可以选择完全相同的模型，并调整训练超参数，也可以选择完全不同的模型，由你决定！

为了让你的结果计入证书，别忘了在训练时使用本单元中展示的以下 `**kwargs` 将你的模型推送到 Hub：

```python
kwargs = {
    "dataset_tags": "marsyas/gtzan",
    "dataset": "GTZAN",
    "model_name": f"{model_name}-finetuned-gtzan",
    "finetuned_from": model_id,
    "tasks": "audio-classification",
}

trainer.push_to_hub(**kwargs)
```

下面是一些额外的资源，希望对你有帮助（均为英文）：
* [Transformers文档中的音频分类任务介绍](https://huggingface.co/docs/transformers/tasks/audio_classification)
* [Hubert模型文档](https://huggingface.co/docs/transformers/model_doc/hubert)
* [M-CTC-T模型文档](https://huggingface.co/docs/transformers/model_doc/mctct)
* [AST（Audio Spectrogram Transformer）文档](https://huggingface.co/docs/transformers/model_doc/audio-spectrogram-transformer)
* [Wav2Vec2文档](https://huggingface.co/docs/transformers/model_doc/wav2vec2)

欢迎在 Discord 上分享你的模型demo！如果你有任何问题，可以在 #audio-study-group 频道中提出。
