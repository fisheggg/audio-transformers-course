# é’ˆå¯¹éŸ³ä¹åˆ†ç±»è¿›è¡Œå¾®è°ƒ

æœ¬å°èŠ‚ä¸­ï¼Œæˆ‘ä»¬ä¼šä¸€æ­¥æ­¥åœ°ä»‹ç»å¦‚ä½•å¾ˆå¯¹éŸ³ä¹åˆ†ç±»ä»»åŠ¡å¾®è°ƒä¸€ä¸ªä»…ç¼–ç å™¨ç»“æ„çš„Transformeræ¨¡å‹ã€‚æˆ‘ä»¬ä¼šä½¿ç”¨ä¸€ä¸ªè½»é‡çº§æ¨¡å‹å’Œä¸€ä¸ªç›¸å¯¹è¾ƒå°çš„æ•°æ®é›†ï¼Œè¿™æ„å‘³ç€ä»£ç å¯ä»¥åœ¨ä»»ä½•æ¶ˆè´¹çº§GPUä¸Šè¿è¡Œï¼ŒåŒ…æ‹¬Google Colabå…è´¹ç‰ˆæä¾›çš„T4 16GB GPUã€‚æˆ‘ä»¬è¿˜ä¼šä»‹ç»ä¸€äº›åœ¨æ›´å°çš„GPUä¸ŠèŠ‚çœå†…å­˜çš„æŠ€å·§ã€‚


## æ•°æ®é›†

æˆ‘ä»¬å°†ä¼šä½¿ç”¨[GTZAN](https://huggingface.co/datasets/marsyas/gtzan)æ•°æ®é›†æ¥è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ã€‚è¿™æ˜¯ä¸€ä¸ªåŒ…å«1000é¦–æ­Œæ›²çš„éŸ³ä¹é£æ ¼åˆ†ç±»æ•°æ®é›†ã€‚æ¯ä¸ªæ ·æœ¬éƒ½æ˜¯30ç§’çš„éŸ³ä¹ç‰‡æ®µï¼Œè¿™äº›ç‰‡æ®µæ¥è‡ª10ç§ä¸åŒçš„éŸ³ä¹é£æ ¼ï¼Œä»è¿ªæ–¯ç§‘åˆ°é‡‘å±ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ğŸ¤— Datasetsçš„`load_dataset()`å‡½æ•°ä»Hugging Face Hubè·å–éŸ³é¢‘æ–‡ä»¶åŠå…¶å¯¹åº”çš„æ ‡ç­¾ï¼š

```python
from datasets import load_dataset

gtzan = load_dataset("marsyas/gtzan", "all")
gtzan
```

**è¾“å‡ºï¼š**
```out
Dataset({
    features: ['file', 'audio', 'genre'],
    num_rows: 999
})
```

<Tip warning={true}>

GTZANçš„å…¶ä¸­ä¸€ä¸ªæ–‡ä»¶æŸåäº†ï¼Œå› æ­¤æˆ‘ä»¬å·²å°†å®ƒç§»é™¤ã€‚å› æ­¤æˆ‘ä»¬åœ¨è¿™é‡Œåªæœ‰999ä¸ªæ ·æœ¬ã€‚

</Tip>

GTZANæ•°æ®é›†æ²¡æœ‰æä¾›ç°æˆçš„éªŒè¯é›†ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦è‡ªå·±åˆ›å»ºä¸€ä¸ªã€‚æ•°æ®é›†åœ¨éŸ³ä¹é£æ ¼ç±»å‹ä¸Šæ˜¯å¹³è¡¡çš„ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥ä½¿ç”¨`train_test_split()`æ–¹æ³•å¿«é€Ÿåˆ›å»ºä¸€ä¸ª90/10çš„åˆ’åˆ†ï¼š

```python
gtzan = gtzan["train"].train_test_split(seed=42, shuffle=True, test_size=0.1)
gtzan
```

**è¾“å‡º**
```out
DatasetDict({
    train: Dataset({
        features: ['file', 'audio', 'genre'],
        num_rows: 899
    })
    test: Dataset({
        features: ['file', 'audio', 'genre'],
        num_rows: 100
    })
})
```

å¾ˆæ£’ï¼Œç°åœ¨æˆ‘ä»¬æœ‰äº†è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼Œè®©æˆ‘ä»¬æ¥çœ‹çœ‹å…¶ä¸­ä¸€ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼š


```python
gtzan["train"][0]
```

**è¾“å‡ºï¼š**
```out
{
    "file": "~/.cache/huggingface/datasets/downloads/extracted/fa06ce46130d3467683100aca945d6deafb642315765a784456e1d81c94715a8/genres/pop/pop.00098.wav",
    "audio": {
        "path": "~/.cache/huggingface/datasets/downloads/extracted/fa06ce46130d3467683100aca945d6deafb642315765a784456e1d81c94715a8/genres/pop/pop.00098.wav",
        "array": array(
            [
                0.10720825,
                0.16122437,
                0.28585815,
                ...,
                -0.22924805,
                -0.20629883,
                -0.11334229,
            ],
            dtype=float32,
        ),
        "sampling_rate": 22050,
    },
    "genre": 7,
}
```

æ­£å¦‚æˆ‘ä»¬åœ¨[ç¬¬ä¸€å•å…ƒ](../chapter1/audio_data)ä¸­çœ‹åˆ°çš„é‚£æ ·ï¼ŒéŸ³é¢‘æ–‡ä»¶è¢«è¡¨ç¤ºä¸ºä¸€ç»´çš„NumPyæ•°ç»„ï¼Œæ•°ç»„çš„æ¯ä¸ªå€¼è¡¨ç¤ºéŸ³é¢‘æ³¢å½¢åœ¨è¯¥æ—¶é—´æ­¥çš„æŒ¯å¹…ã€‚è¿™äº›éŸ³é¢‘çš„é‡‡æ ·ç‡ä¸º22,050 Hzï¼Œå³æ¯ç§’é’Ÿé‡‡æ ·22,050ä¸ªæŒ¯å¹…å€¼ã€‚å½“æˆ‘ä»¬ä½¿ç”¨ä¸åŒé‡‡æ ·ç‡çš„é¢„è®­ç»ƒæ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬éœ€è¦æ³¨æ„å…¶é‡‡æ ·ç‡çš„åŒºåˆ«ï¼Œé€šè¿‡è½¬æ¢é‡‡æ ·ç‡æ¥ç¡®ä¿å®ƒä»¬åŒ¹é…ã€‚æˆ‘ä»¬è¿˜å¯ä»¥çœ‹åˆ°éŸ³ä¹é£æ ¼è¢«è¡¨ç¤ºä¸ºæ•´æ•°ï¼Œæˆ–è€…è¯´æ˜¯ä¸€ä¸ª_ç±»æ ‡ç­¾_ï¼Œè¿™æ˜¯æ¨¡å‹è¿›è¡Œé¢„æµ‹çš„æ ¼å¼ã€‚è®©æˆ‘ä»¬ä½¿ç”¨`genre`ç‰¹å¾çš„`int2str()`æ–¹æ³•å°†è¿™äº›æ•´æ•°æ˜ å°„åˆ°å¯è¯»çš„åç§°ï¼š


```python
id2label_fn = gtzan["train"].features["genre"].int2str
id2label_fn(gtzan["train"][0]["genre"])
```

**è¾“å‡ºï¼š**
```out
'pop'
```

æˆ‘ä»¬çš„æ ‡ç­¾çœ‹èµ·æ¥æ˜¯æ­£ç¡®çš„ï¼Œå› ä¸ºå®ƒä¸éŸ³é¢‘æ–‡ä»¶çš„æ–‡ä»¶ååŒ¹é…ã€‚ç°åœ¨è®©æˆ‘ä»¬ä½¿ç”¨`Blocks` APIæ¥åˆ›å»ºä¸€ä¸ªç®€å•çš„ç•Œé¢ï¼Œé€šè¿‡Gradioæ¥æŸ¥çœ‹æ›´å¤šçš„ä¾‹å­ï¼š

```python
def generate_audio():
    example = gtzan["train"].shuffle()[0]
    audio = example["audio"]
    return (
        audio["sampling_rate"],
        audio["array"],
    ), id2label_fn(example["genre"])


with gr.Blocks() as demo:
    with gr.Column():
        for _ in range(4):
            audio, label = generate_audio()
            output = gr.Audio(audio, label=label)

demo.launch(debug=True)
```

<iframe src="https://course-demos-gtzan-samples.hf.space" frameBorder="0" height="450" title="Gradio app" class="container p-0 flex-grow space-iframe" allow="accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking" sandbox="allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"></iframe>

æˆ‘ä»¬å¯ä»¥å¬å‡ºä¸åŒé£æ ¼çš„éŸ³ä¹ä¹‹é—´çš„å·®å¼‚ï¼Œä½†Transformerèƒ½å¤Ÿåšåˆ°è¿™ä¸€ç‚¹å—ï¼Ÿè®©æˆ‘ä»¬è®­ç»ƒä¸€ä¸ªæ¨¡å‹è¯•è¯•å§ï¼é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦æ‰¾åˆ°ä¸€ä¸ªé€‚åˆè¿™ä¸ªä»»åŠ¡çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚

## éŸ³é¢‘åˆ†ç±»é¢„è®­ç»ƒæ¨¡å‹çš„é€‰æ‹©

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦é€‰æ‹©ä¸€ä¸ªé€‚åˆéŸ³é¢‘åˆ†ç±»ä»»åŠ¡çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚é€šå¸¸é¢„è®­ç»ƒæ˜¯åœ¨å¤§é‡çš„æ— æ ‡ç­¾çš„éŸ³é¢‘æ•°æ®ä¸Šè¿›è¡Œçš„ï¼Œä½¿ç”¨çš„æ•°æ®é›†åŒ…æ‹¬[LibriSpeech](https://huggingface.co/datasets/librispeech_asr)å’Œ[Voxpopuli](https://huggingface.co/datasets/facebook/voxpopuli)ç­‰ã€‚å¦‚ä¸Šä¸€èŠ‚æ‰€è¿°ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨"Audio Classification"è¿‡æ»¤å™¨åœ¨Hugging Face Hubä¸Šæ‰¾åˆ°è¿™äº›æ¨¡å‹ã€‚è™½ç„¶Wav2Vec2å’ŒHuBERTç­‰æ¨¡å‹éå¸¸æµè¡Œï¼Œä½†æˆ‘ä»¬åœ¨æœ¬èŠ‚ä¼šä½¿ç”¨ä¸€ä¸ªåä¸º_DistilHuBERT_çš„æ¨¡å‹ã€‚è¿™æ˜¯[HubERT](https://huggingface.co/docs/transformers/model_doc/hubert)æ¨¡å‹çš„ä¸€ä¸ªè½»é‡ï¼ˆåˆç§°_è’¸é¦_ï¼‰ç‰ˆæœ¬ï¼Œå…¶è®­ç»ƒé€Ÿåº¦æ¯”åŸç‰ˆå¿«73%ï¼Œä¸”ä¿ç•™äº†åŸç‰ˆçš„å¤§éƒ¨åˆ†æ€§èƒ½ã€‚

<iframe src="https://autoevaluate-leaderboards.hf.space" frameBorder="0" height="450" title="Gradio app" class="container p-0 flex-grow space-iframe" allow="accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking" sandbox="allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"></iframe>

## éŸ³é¢‘ç‰¹å¾æå–

## æ•°æ®é¢„å¤„ç†

å’ŒNLPä¸­çš„æ ‡è®°åŒ–ï¼ˆtokenizationï¼‰ç±»ä¼¼ï¼Œæˆ‘ä»¬åœ¨éŸ³é¢‘å’Œè¯­éŸ³ä¸­ä¹Ÿéœ€è¦å°†è¾“å…¥ç¼–ç ä¸ºæ¨¡å‹å¯ä»¥å¤„ç†çš„æ ¼å¼ã€‚åœ¨ğŸ¤— Transformersä¸­ï¼Œå°†éŸ³é¢‘è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼çš„è¿‡ç¨‹ç”±æ¨¡å‹çš„_feature extractor_æ¥å¤„ç†ã€‚ä¸tokenizerç±»ä¼¼ï¼ŒğŸ¤— Transformersæä¾›äº†ä¸€ä¸ªæ–¹ä¾¿çš„`AutoFeatureExtractor`ç±»ï¼Œå¯ä»¥è‡ªåŠ¨é€‰æ‹©ç»™å®šæ¨¡å‹çš„æ­£ç¡®ç‰¹å¾æå–å™¨ã€‚ä¸ºäº†å±•ç¤ºå¦‚ä½•å¤„ç†éŸ³é¢‘æ–‡ä»¶ï¼Œè®©æˆ‘ä»¬é¦–å…ˆä»é¢„è®­ç»ƒè¿‡çš„æ¨¡å‹æ£€æŸ¥ç‚¹ä¸­å®ä¾‹åŒ–DistilHuBERTçš„ç‰¹å¾æå–å™¨ï¼š


```python
from transformers import AutoFeatureExtractor

model_id = "ntu-spml/distilhubert"
feature_extractor = AutoFeatureExtractor.from_pretrained(
    model_id, do_normalize=True, return_attention_mask=True
)
```

ç”±äºè¯¥é¢„è®­ç»ƒæ¨¡å‹çš„é‡‡æ ·ç‡ä¸æˆ‘ä»¬ä½¿ç”¨çš„æ•°æ®é›†ä¸åŒï¼Œæˆ‘ä»¬éœ€è¦åœ¨æŠŠéŸ³é¢‘æ–‡ä»¶è¾“å…¥ç»™ç‰¹å¾æå–å…¶ä¹‹å‰å°†å…¶é‡é‡‡æ ·è‡³16,000 Hzã€‚æˆ‘ä»¬å…ˆæ¥çœ‹çœ‹æ¨¡å‹çš„é‡‡æ ·ç‡ï¼š

```python
sampling_rate = feature_extractor.sampling_rate
sampling_rate
```

**è¾“å‡ºï¼š**
```out
16000
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨`cast_column()`æ–¹æ³•å’ŒğŸ¤— Datasetsçš„`Audio`åŠŸèƒ½å¯¹æ•°æ®é›†è¿›è¡Œé‡é‡‡æ ·ï¼š

```python
from datasets import Audio

gtzan = gtzan.cast_column("audio", Audio(sampling_rate=sampling_rate))
```

ç°åœ¨æˆ‘ä»¬å¯ä»¥æ£€æŸ¥æ•°æ®é›†çš„ç¬¬ä¸€ä¸ªæ ·æœ¬æ˜¯å¦ç¡®å®æ˜¯16,000 Hzã€‚ğŸ¤— Datasetsä¼šåœ¨åŠ è½½æ¯ä¸ªéŸ³é¢‘æ ·æœ¬æ—¶_å³æ—¶_å¯¹å…¶è¿›è¡Œé‡é‡‡æ ·ï¼š

```python
gtzan["train"][0]
```

**è¾“å‡ºï¼š**
```out
{
    "file": "~/.cache/huggingface/datasets/downloads/extracted/fa06ce46130d3467683100aca945d6deafb642315765a784456e1d81c94715a8/genres/pop/pop.00098.wav",
    "audio": {
        "path": "~/.cache/huggingface/datasets/downloads/extracted/fa06ce46130d3467683100aca945d6deafb642315765a784456e1d81c94715a8/genres/pop/pop.00098.wav",
        "array": array(
            [
                0.0873509,
                0.20183384,
                0.4790867,
                ...,
                -0.18743178,
                -0.23294401,
                -0.13517427,
            ],
            dtype=float32,
        ),
        "sampling_rate": 16000,
    },
    "genre": 7,
}
```

å¾ˆæ£’ï¼æˆ‘ä»¬çœ‹åˆ°éŸ³é¢‘çš„é‡‡æ ·ç‡å·²ç»ä¸‹é™åˆ°äº†16kHzã€‚æ•°ç»„ä¸­å…ƒç´ çš„å€¼ä¹Ÿæœ‰æ‰€å˜åŒ–ï¼Œè¿™æ˜¯å› ä¸ºæˆ‘ä»¬åœ¨å¤§çº¦1.5ä¸ªåŸå§‹é‡‡æ ·ç‚¹çš„æ—¶é—´èŒƒå›´å†…åªæœ‰1ä¸ªå€¼ã€‚

Wav2Vec2å’ŒHuBERTç­‰æ¨¡å‹çš„ä¸€ä¸ªæ˜¾è‘—ç‰¹å¾æ˜¯å®ƒä»¬çš„è¾“å…¥æ˜¯åŸå§‹çš„éŸ³é¢‘æ³¢å½¢æ•°ç»„ï¼Œè€ŒWhisperç­‰å…¶ä»–æ¨¡å‹åˆ™ä½¿ç”¨éŸ³é¢‘å¤„ç†å¾—åˆ°çš„æ—¶é¢‘è°±å›¾ä½œä¸ºè¾“å…¥ã€‚

æˆ‘ä»¬æåˆ°è¿‡éŸ³é¢‘æ•°æ®è¢«è¡¨ç¤ºä¸ºä¸€ç»´æ•°ç»„ï¼Œå› æ­¤å®ƒå·²ç»æ˜¯æ¨¡å‹å¯ä»¥è¯»å–çš„æ­£ç¡®æ ¼å¼ï¼ˆä¸€ç»„åœ¨æ—¶é—´ä¸Šç¦»æ•£ä½†å¹…å€¼ä¸Šè¿ç»­çš„æ•°å€¼ï¼‰ã€‚é‚£ä¹ˆç‰¹å¾æå–å™¨åˆ°åº•åšäº†ä»€ä¹ˆå‘¢ï¼Ÿ

è™½ç„¶æˆ‘ä»¬çš„è¾“å…¥æ ¼å¼å·²ç»æ˜¯æ­£ç¡®çš„ï¼Œä½†æ•°æ®çš„å–å€¼èŒƒå›´å¹¶æ²¡æœ‰è¢«é™åˆ¶ã€‚ä¸ºäº†è®©æ¨¡å‹åœ¨ç†æƒ³æƒ…å†µä¸‹å·¥ä½œï¼Œæˆ‘ä»¬éœ€è¦è®©å…¨éƒ¨è¾“å…¥ä¿æŒåœ¨ç›¸åŒçš„åŠ¨æ€èŒƒå›´å†…ã€‚è¿™å¯ä»¥ç¡®ä¿ç¥ç»å…ƒçš„æ¿€æ´»æƒ…å†µå’Œæ¢¯åº¦èŒƒå›´ä¿æŒä¸€è‡´ï¼Œä»è€Œæœ‰åŠ©äºè®­ç»ƒçš„ç¨³å®šæ€§å’Œæ¨¡å‹çš„æ”¶æ•›ã€‚

ä¸ºäº†åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬éœ€è¦å¯¹éŸ³é¢‘æ•°æ®è¿›è¡Œ_å½’ä¸€åŒ–_ï¼ˆnormalizationï¼‰ï¼Œå³å°†æ¯ä¸ªæ ·æœ¬é‡æ–°ç¼©æ”¾è‡³é›¶å‡å€¼å’Œå•ä½æ–¹å·®ï¼Œè¿™ä¸ªè¿‡ç¨‹ç§°ä¸º_ç‰¹å¾ç¼©æ”¾_ï¼ˆfeature scalingï¼‰ã€‚æˆ‘ä»¬çš„ç‰¹å¾æå–å™¨è¿›è¡Œçš„å¤„ç†æ­£æ˜¯ç‰¹å¾ç¼©æ”¾ï¼

è®©æˆ‘ä»¬æ¥çœ‹çœ‹ç‰¹å¾æå–å™¨å¯¹ç¬¬ä¸€ä¸ªæ ·æœ¬è¿›è¡Œäº†ä»€ä¹ˆå¤„ç†ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬è®¡ç®—è¯¥æ ·æœ¬å¤„ç†å‰çš„å‡å€¼å’Œæ–¹å·®ï¼š

```python
import numpy as np

sample = gtzan["train"][0]["audio"]

print(f"Mean: {np.mean(sample['array']):.3}, Variance: {np.var(sample['array']):.3}")
```

**è¾“å‡ºï¼š**
```out
Mean: 0.000185, Variance: 0.0493
```

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°å‡å€¼å·²ç»æ¥è¿‘äºé›¶ï¼Œä½†æ–¹å·®æ¥è¿‘äº0.05ã€‚å¦‚æœæ ·æœ¬çš„æ–¹å·®è¿‡å¤§ï¼Œå®ƒå¯èƒ½ä¼šç»™æˆ‘ä»¬çš„æ¨¡å‹å¸¦æ¥é—®é¢˜ï¼Œå› ä¸ºéŸ³é¢‘æ•°æ®çš„åŠ¨æ€èŒƒå›´ä¼šéå¸¸å°ï¼Œä»è€Œéš¾ä»¥åˆ†ç¦»ã€‚ç°åœ¨æˆ‘ä»¬ä½¿ç”¨ç‰¹å¾æå–å™¨ï¼Œçœ‹çœ‹æœ‰ä»€ä¹ˆå˜åŒ–ï¼š

```python
inputs = feature_extractor(sample["array"], sampling_rate=sample["sampling_rate"])

print(f"inputs keys: {list(inputs.keys())}")

print(
    f"Mean: {np.mean(inputs['input_values']):.3}, Variance: {np.var(inputs['input_values']):.3}"
)
```

**è¾“å‡ºï¼š**
```out
inputs keys: ['input_values', 'attention_mask']
Mean: -4.53e-09, Variance: 1.0
```

ç‰¹å¾æå–å™¨è¿”å›äº†ä¸¤ä¸ªæ•°ç»„ï¼š`input_values`å’Œ`attention_mask`ã€‚`input_values`æ˜¯æˆ‘ä»¬å°†ä¼ é€’ç»™HuBERTæ¨¡å‹çš„é¢„å¤„ç†åçš„éŸ³é¢‘è¾“å…¥ã€‚[`attention_mask`](https://huggingface.co/docs/transformers/glossary#attention-mask)ç”¨äºåœ¨ä¸€æ¬¡å¤„ç†å¤šä¸ªéŸ³é¢‘è¾“å…¥æ—¶å‘Šè¯‰æ¨¡å‹æ¯ä¸ªè¾“å…¥çš„ä¸åŒé•¿çŸ­ã€‚

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°å‡å€¼å·²ç»éå¸¸æ¥è¿‘äºé›¶ï¼Œæ–¹å·®å®Œå…¨ç­‰äº1ï¼è¿™æ­£æ˜¯æˆ‘ä»¬å¸Œæœ›åœ¨å°†éŸ³é¢‘æ ·æœ¬è¾“é€åˆ°HuBERTæ¨¡å‹ä¹‹å‰çœ‹åˆ°çš„å½¢å¼ã€‚

<Tip warning={true}>

æ³¨æ„æˆ‘ä»¬å·²ç»å°†éŸ³é¢‘çš„é‡‡æ ·ç‡ä¼ é€’ç»™äº†ç‰¹å¾æå–å™¨ã€‚è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„åšæ³•ï¼Œå› ä¸ºç‰¹å¾æå–å™¨ä¼šåœ¨å†…éƒ¨æ‰§è¡Œä¸€ä¸ªæ£€æŸ¥ï¼Œä»¥ç¡®ä¿éŸ³é¢‘æ•°æ®çš„é‡‡æ ·ç‡ä¸æ¨¡å‹æœŸæœ›çš„é‡‡æ ·ç‡ç›¸åŒ¹é…ã€‚å¦‚æœå®ƒä»¬ä¸åŒ¹é…ï¼Œæˆ‘ä»¬éœ€è¦å°†éŸ³é¢‘æ•°æ®ä¸Šé‡‡æ ·æˆ–ä¸‹é‡‡æ ·åˆ°æ­£ç¡®çš„é‡‡æ ·ç‡ã€‚

</Tip>

æœ€åï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œå°†é¢„å¤„ç†è¿‡ç¨‹åº”ç”¨åˆ°æ•°æ®é›†ä¸­çš„æ‰€æœ‰æ ·æœ¬ä¸Šã€‚åŒæ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨ç‰¹å¾æå–å™¨çš„`max_length`å’Œ`truncation`å‚æ•°æ¥ä¿è¯éŸ³é¢‘çš„é•¿åº¦ä¸º30ç§’ï¼š


```python
max_duration = 30.0


def preprocess_function(examples):
    audio_arrays = [x["array"] for x in examples["audio"]]
    inputs = feature_extractor(
        audio_arrays,
        sampling_rate=feature_extractor.sampling_rate,
        max_length=int(feature_extractor.sampling_rate * max_duration),
        truncation=True,
        return_attention_mask=True,
    )
    return inputs
```

å®Œæˆå‡½æ•°å®šä¹‰åï¼Œæˆ‘ä»¬ä½¿ç”¨`map()`æ–¹æ³•å°†å…¶åº”ç”¨åˆ°æ•°æ®é›†ä¸Šï¼š

```python
gtzan_encoded = gtzan.map(
    preprocess_function, remove_columns=["audio", "file"], batched=True, num_proc=1
)
gtzan_encoded
```

**è¾“å‡ºï¼š**
```out
DatasetDict({
    train: Dataset({
        features: ['genre', 'input_values'],
        num_rows: 899
    })
    test: Dataset({
        features: ['genre', 'input_values'],
        num_rows: 100
    })
})
```

ä¸ºäº†ç®€åŒ–è®­ç»ƒï¼Œæˆ‘ä»¬ä»æ•°æ®é›†ä¸­åˆ é™¤äº†`audio`å’Œ`file`åˆ—ã€‚`input_values`åˆ—åŒ…å«ç¼–ç åçš„éŸ³é¢‘æ–‡ä»¶ï¼Œ`attention_mask`æ˜¯ä¸€ä¸ªäºŒè¿›åˆ¶æ©ç ï¼Œå…¶ä¸­0/1å€¼è¡¨ç¤ºè¾“å…¥ä¸­çš„å¯¹åº”ä½ç½®æ˜¯å¦åŒ…å«äº†è¾“å…¥å†…å®¹ï¼Œ`genre`åˆ—åŒ…å«ç›¸åº”çš„æ ‡ç­¾ï¼ˆæˆ–ç›®æ ‡ï¼‰ã€‚ä¸ºäº†è®©`Trainer`èƒ½å¤Ÿå¤„ç†ç±»æ ‡ç­¾ï¼Œæˆ‘ä»¬éœ€è¦å°†`genre`åˆ—é‡å‘½åä¸º`label`ï¼š

```python
gtzan_encoded = gtzan_encoded.rename_column("genre", "label")
```

æœ€åï¼Œæˆ‘ä»¬éœ€è¦ä»æ•°æ®é›†ä¸­è·å–æ ‡ç­¾çš„æ˜ å°„ã€‚è¿™ä¸ªæ˜ å°„å°†æ•´æ•°idï¼ˆä¾‹å¦‚`7`ï¼‰è½¬æ¢ä¸ºå¯è¯»çš„æ–‡å­—æ ‡ç­¾ï¼ˆä¾‹å¦‚`"pop"`ï¼‰ï¼Œä»¥åŠåå‘è½¬æ¢ã€‚è¿™æ ·åšçš„å¥½å¤„æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ¨¡å‹çš„æ•´æ•°idé¢„æµ‹è½¬æ¢ä¸ºå¯è¯»çš„æ ¼å¼ï¼Œä»è€Œä½¿æˆ‘ä»¬å¯ä»¥åœ¨ä»»ä½•ä¸‹æ¸¸åº”ç”¨ä¸­ä½¿ç”¨æ¨¡å‹ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨`int2str()`æ–¹æ³•æ¥å®Œæˆè¿™ä¸ªæ˜ å°„ï¼š

```python
id2label = {
    str(i): id2label_fn(i)
    for i in range(len(gtzan_encoded["train"].features["label"].names))
}
label2id = {v: k for k, v in id2label.items()}

id2label["7"]
```

```out
'pop'
```

ç°åœ¨æˆ‘ä»¬çš„æ•°æ®é›†å·²ç»å‡†å¤‡å¥½äº†ï¼è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•ä½¿ç”¨å®ƒæ¥è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ã€‚

## æ¨¡å‹å¾®è°ƒï¼ˆfine-tuningï¼‰

æˆ‘ä»¬ä½¿ç”¨ğŸ¤— Transformersçš„`Trainer`ç±»æ¥å¾®è°ƒæ¨¡å‹ã€‚`Trainer`æ˜¯ä¸€ä¸ªç”¨æ¥å¤„ç†å¸¸è§çš„è®­ç»ƒä»»åŠ¡çš„é«˜çº§APIã€‚è¿™é‡Œæˆ‘ä»¬å°†ä½¿ç”¨`Trainer`æ¥åœ¨GTZANä¸Šå¾®è°ƒæ¨¡å‹ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦åŠ è½½ä¸€ä¸ªé€‚åˆè¿™ä¸ªä»»åŠ¡çš„æ¨¡å‹ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨`AutoModelForAudioClassification`ç±»æ¥å®ç°è¿™ä¸€ç‚¹ï¼Œå®ƒä¼šè‡ªåŠ¨ä¸ºæˆ‘ä»¬çš„é¢„è®­ç»ƒDistilHuBERTæ¨¡å‹æ·»åŠ é€‚å½“çš„åˆ†ç±»å¤´ã€‚è®©æˆ‘ä»¬æ¥å®ä¾‹åŒ–æ¨¡å‹ï¼š

```python
from transformers import AutoModelForAudioClassification

num_labels = len(id2label)

model = AutoModelForAudioClassification.from_pretrained(
    model_id,
    num_labels=num_labels,
    label2id=label2id,
    id2label=id2label,
)
```

æˆ‘ä»¬å¼ºçƒˆå»ºè®®åœ¨è®­ç»ƒä¸­å°†æ¨¡å‹çš„æ£€æŸ¥ç‚¹ç›´æ¥ä¸Šä¼ åˆ°[Hugging Face Hub](https://huggingface.co/)ã€‚Hubæä¾›äº†ï¼š
- å†…ç½®æœ¬ç‰ˆç®¡ç†ï¼šç¡®ä¿è®­ç»ƒä¸­çš„æ£€æŸ¥ç‚¹ä¸ä¼šä¸¢å¤±ã€‚
- Tensorboard æ—¥å¿—ï¼šè·Ÿè¸ªè®­ç»ƒè¿‡ç¨‹ä¸­çš„é‡è¦æŒ‡æ ‡ã€‚
- æ¨¡å‹å¡ç‰‡ï¼šè®°å½•æ¨¡å‹çš„åŠŸèƒ½å’Œä½¿ç”¨æ–¹æ³•ã€‚
- ç¤¾åŒºï¼šå’Œç¤¾åŒºä¸­çš„å°ä¼™ä¼´åˆ†äº«ã€åˆä½œï¼ ğŸ¤—

æˆ‘ä»¬å¯ä»¥æ–¹ä¾¿åœ°å°†Jupyter notebookä¸Hubè¿æ¥èµ·æ¥ï¼Œåªéœ€è¦åœ¨notebookä¸­è¾“å…¥ä½ çš„Hubä»¤ç‰Œã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†ä½¿ç”¨`notebook_login()`å‡½æ•°æ¥è¿æ¥Hubï¼Œè¿™ä¸ªå‡½æ•°ä¼šåœ¨notebookä¸­å¼¹å‡ºä¸€ä¸ªçª—å£ï¼Œè®©ä½ è¾“å…¥ä½ çš„Hubä»¤ç‰Œã€‚ä½ å¯ä»¥åœ¨[è¿™é‡Œ](https://huggingface.co/settings/tokens)æ‰¾åˆ°ä½ çš„Hubä»¤ç‰Œï¼š

```python
from huggingface_hub import notebook_login

notebook_login()
```

**Output:**
```bash
Login successful
Your token has been saved to /root/.huggingface/token
```

æ¥ä¸‹æ¥æˆ‘ä»¬éœ€è¦å®šä¹‰è®­ç»ƒå‚æ•°ï¼ŒåŒ…æ‹¬æ‰¹æ¬¡å¤§å°ï¼ˆbatch sizeï¼‰ã€æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼ˆgradient accumulation stepsï¼‰ã€è®­ç»ƒä»£æ•°ï¼ˆtraining epochsï¼‰å’Œå­¦ä¹ ç‡ï¼ˆlearning rateï¼‰ï¼š


```python
from transformers import TrainingArguments

model_name = model_id.split("/")[-1]
batch_size = 8
gradient_accumulation_steps = 1
num_train_epochs = 10

training_args = TrainingArguments(
    f"{model_name}-finetuned-gtzan",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=5e-5,
    per_device_train_batch_size=batch_size,
    gradient_accumulation_steps=gradient_accumulation_steps,
    per_device_eval_batch_size=batch_size,
    num_train_epochs=num_train_epochs,
    warmup_ratio=0.1,
    logging_steps=5,
    load_best_model_at_end=True,
    metric_for_best_model="accuracy",
    fp16=True,
    push_to_hub=True,
)
```

<Tip warning={true}>

    è¿™é‡Œæˆ‘ä»¬è®¾ç½®äº†`push_to_hub=True`ï¼Œä»¥ä¾¿åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è‡ªåŠ¨ä¸Šä¼ å¾®è°ƒåçš„æ£€æŸ¥ç‚¹ã€‚å¦‚æœä½ ä¸å¸Œæœ›ä½ çš„æ£€æŸ¥ç‚¹ä¸Šä¼ åˆ°Hubï¼Œå¯ä»¥å°†å…¶è®¾ç½®ä¸º`False`ã€‚

</Tip>

æœ€åï¼Œæˆ‘ä»¬æ¥å®šä¹‰è®­ç»ƒçš„æŒ‡æ ‡ã€‚ç”±äºæˆ‘ä»¬çš„æ•°æ®é›†åœ¨ä¸åŒçš„ç±»ä¸Šåˆ†å¸ƒå‡åŒ€ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å‡†ç¡®ç‡ï¼ˆaccuracyï¼‰ä½œä¸ºæŒ‡æ ‡ã€‚æˆ‘ä»¬å¯ä»¥ç”¨ğŸ¤— Evaluateåº“åŠ è½½æŒ‡æ ‡ï¼š


```python
import evaluate

metric = evaluate.load("accuracy")


def compute_metrics(eval_pred):
    """Computes accuracy on a batch of predictions"""
    predictions = np.argmax(eval_pred.predictions, axis=1)
    return metric.compute(predictions=predictions, references=eval_pred.label_ids)
```

æ‹¼å›¾å·²ç»å®Œæˆäº†ï¼æˆ‘ä»¬ç°åœ¨æœ‰äº†æ‰€æœ‰çš„ç»„ä»¶ã€‚è®©æˆ‘ä»¬å®ä¾‹åŒ–`Trainer`å¹¶å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼š


```python
from transformers import Trainer

trainer = Trainer(
    model,
    training_args,
    train_dataset=gtzan_encoded["train"],
    eval_dataset=gtzan_encoded["test"],
    tokenizer=feature_extractor,
    compute_metrics=compute_metrics,
)

trainer.train()
```

<Tip warning={true}>

ä¸€äº›GPUå¯èƒ½ä¼šå‡ºç°CUDAå†…å­˜ä¸è¶³çš„é”™è¯¯ï¼ˆ`"out-of-memory"`ï¼‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½ å¯ä»¥å°†`batch_size`é€æ­¥å‡å°‘ï¼Œå¹¶ä½¿ç”¨[`gradient_accumulation_steps`](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments.gradient_accumulation_steps)æ¥è¡¥å¿ã€‚

</Tip>

**è¾“å‡ºï¼š**
```out
| Training Loss | Epoch | Step | Validation Loss | Accuracy |
|:-------------:|:-----:|:----:|:---------------:|:--------:|
| 1.7297        | 1.0   | 113  | 1.8011          | 0.44     |
| 1.24          | 2.0   | 226  | 1.3045          | 0.64     |
| 0.9805        | 3.0   | 339  | 0.9888          | 0.7      |
| 0.6853        | 4.0   | 452  | 0.7508          | 0.79     |
| 0.4502        | 5.0   | 565  | 0.6224          | 0.81     |
| 0.3015        | 6.0   | 678  | 0.5411          | 0.83     |
| 0.2244        | 7.0   | 791  | 0.6293          | 0.78     |
| 0.3108        | 8.0   | 904  | 0.5857          | 0.81     |
| 0.1644        | 9.0   | 1017 | 0.5355          | 0.83     |
| 0.1198        | 10.0  | 1130 | 0.5716          | 0.82     |
```

è®­ç»ƒè¿‡ç¨‹å¤§æ¦‚ä¼šæŒç»­1ä¸ªå°æ—¶å·¦å³ï¼Œæ ¹æ®æœ¬åœ°GPUæˆ–Google Colabåˆ†é…çš„GPUçš„ç®—åŠ›ä¸åŒå¯èƒ½ä¼šæœ‰æ‰€æµ®åŠ¨ã€‚æˆ‘ä»¬æ‰€å¾—åˆ°çš„æœ€ä½³è¯„ä¼°é›†å‡†ç¡®ç‡ä¸º83%â€”â€”å¯¹äºåªè®­ç»ƒäº†10ä»£ã€åªæœ‰899ä¸ªè®­ç»ƒæ ·æœ¬çš„æ¨¡å‹æ¥è¯´ï¼Œè¿™ä¸ªç»“æœè¿˜ä¸é”™ï¼æˆ‘ä»¬å½“ç„¶å¯ä»¥é€šè¿‡è®­ç»ƒæ›´å¤šçš„ä»£ï¼ˆepochï¼‰ã€ä½¿ç”¨_éšæœºå¤±æ´»_ï¼ˆdropoutï¼‰ç­‰æ­£åˆ™åŒ–æŠ€æœ¯ï¼Œæˆ–è€…å°†æ¯ä¸ªéŸ³é¢‘æ ·æœ¬ä»30ç§’åˆ’åˆ†ä¸ºä¸¤ä¸ª15ç§’çš„ç‰‡æ®µç­‰æ–¹æ³•è¿›ä¸€æ­¥ä¼˜åŒ–ç»“æœã€‚

æˆ‘ä»¬æƒ³çŸ¥é“è¿™ä¸ªç»“æœä¸å…¶ä»–éŸ³ä¹åˆ†ç±»ç³»ç»Ÿç›¸æ¯”å¦‚ä½•ğŸ¤”ã€‚æˆ‘ä»¬å¯ä»¥åœ¨[è‡ªåŠ¨è¯„ä»·æ’è¡Œæ¦œ](https://huggingface.co/spaces/autoevaluate/leaderboards?dataset=marsyas%2Fgtzan&only_verified=0&task=audio-classification&config=all&split=train&metric=accuracy)ä¸ŠæŸ¥çœ‹ã€‚è¯¥æ¦œå•æ ¹æ®æ¨¡å‹çš„è¯­è¨€å’Œä½¿ç”¨çš„æ•°æ®é›†è¿›è¡Œåˆ†æ¦œï¼Œå¹¶æ ¹æ®å‡†ç¡®ç‡å¯¹æ¨¡å‹è¿›è¡Œæ’åã€‚

æˆ‘ä»¬å¯ä»¥å°†è®­ç»ƒå¥½çš„æ¨¡å‹æ£€æŸ¥ç‚¹è‡ªåŠ¨ä¸Šä¼ åˆ°æ’è¡Œæ¦œä¸Šï¼Œåªéœ€è¦è®¾ç½®å¯¹åº”çš„å…³é”®è¯å‚æ•°ï¼ˆkwargsï¼‰å³å¯ã€‚ä½ å¯ä»¥æ ¹æ®ä½ çš„æ•°æ®é›†ã€è¯­è¨€å’Œæ¨¡å‹åç§°æ¥æ›´æ”¹è¿™äº›å€¼ï¼š
```python
kwargs = {
    "dataset_tags": "marsyas/gtzan",
    "dataset": "GTZAN",
    "model_name": f"{model_name}-finetuned-gtzan",
    "finetuned_from": model_id,
    "tasks": "audio-classification",
}
```

ç°åœ¨æˆ‘ä»¬å¯ä»¥æŠŠè®­ç»ƒç»“æœä¸Šä¼ åˆ°Hubä¸Šã€‚æˆ‘ä»¬æ‰§è¡Œ`.push_to_hub()`å‡½æ•°ï¼š

```python
trainer.push_to_hub(**kwargs)
```

è¯¥å‘½ä»¤ä¼šæŠŠæˆ‘ä»¬çš„è®­ç»ƒæ—¥å¿—å’Œæ¨¡å‹æƒé‡ä¸Šä¼ åˆ°Hubä¸Šã€‚å¯¹äºè¿™ä¸ªä¾‹å­ï¼Œå®ƒä¼šæŠŠè®­ç»ƒæ—¥å¿—å’Œæ¨¡å‹æƒé‡ä¸Šä¼ åˆ°`"your-username/distilhubert-finetuned-gtzan"`ä¸‹ã€‚ä½ å¯ä»¥åœ¨[`"sanchit-gandhi/distilhubert-finetuned-gtzan"`](https://huggingface.co/sanchit-gandhi/distilhubert-finetuned-gtzan)æ‰¾åˆ°è¿™æ¬¡è®­ç»ƒçš„ç»“æœã€‚


## åˆ†äº«æ¨¡å‹

ç°åœ¨ä½ å¯ä»¥ä½¿ç”¨Hubé“¾æ¥å’Œä»»ä½•äººåˆ†äº«è¿™ä¸ªæ¨¡å‹ã€‚åªéœ€è¦åœ¨`pipeline()`ç±»ä¸­ä½¿ç”¨`"your-username/distilhubert-finetuned-gtzan"`è·¯å¾„å³å¯ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥åŠ è½½[`"sanchit-gandhi/distilhubert-finetuned-gtzan"`](https://huggingface.co/sanchit-gandhi/distilhubert-finetuned-gtzan)ä¸­çš„å¾®è°ƒæ¨¡å‹ï¼š

```python
from transformers import pipeline

pipe = pipeline(
    "audio-classification", model="sanchit-gandhi/distilhubert-finetuned-gtzan"
)
```

## æ€»ç»“

æœ¬å°èŠ‚ä¸­ï¼Œæˆ‘ä»¬è¯¦ç»†åœ°ä»‹ç»äº†å¦‚ä½•åœ¨éŸ³ä¹åˆ†ç±»ä»»åŠ¡ä¸Šå¾®è°ƒDistilHuBERTæ¨¡å‹ã€‚è™½ç„¶æœ¬èŠ‚ä¸­æˆ‘ä»¬ä»‹ç»çš„æ˜¯éŸ³ä¹åˆ†ç±»ä»»åŠ¡å’ŒGTZANæ•°æ®é›†ï¼Œä½†æˆ‘ä»¬ä»‹ç»è¿‡çš„è®­ç»ƒæ­¥éª¤å¯ä»¥åº”ç”¨åœ¨ä»»ä½•éŸ³é¢‘åˆ†ç±»ä»»åŠ¡ä¸Šã€‚åŒæ ·çš„ä»£ç ä¹Ÿå¯ä»¥åº”ç”¨åœ¨è®¸å¤šè¯­éŸ³åˆ†ç±»ä»»åŠ¡ä¸Šï¼Œä¾‹å¦‚å…³é”®è¯æ£€æµ‹æˆ–è¯­è¨€åˆ†ç±»ã€‚åªéœ€è¦æŠŠæ•°æ®é›†æ¢æˆä½ æƒ³è¦çš„ä»»åŠ¡çš„æ•°æ®é›†å³å¯ï¼å¦‚æœä½ æƒ³äº†è§£æ›´å¤šå…¶ä»–çš„éŸ³é¢‘åˆ†ç±»ä»»åŠ¡ï¼Œå¯ä»¥æŸ¥çœ‹æˆ‘ä»¬åœ¨ğŸ¤— Transformersåº“ä¸­çš„[å…¶ä»–ä¾‹å­](https://github.com/huggingface/transformers/tree/main/examples/pytorch/audio-classification)ã€‚

åœ¨ä¸‹ä¸€å°èŠ‚ä¸­ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨æœ¬å°èŠ‚ä¸­å¾®è°ƒè¿‡çš„æ¨¡å‹æ­å»ºä¸€ä¸ªéŸ³ä¹åˆ†ç±»demoï¼Œå¹¶åˆ†äº«åˆ°Hugging Face Hubä¸Šã€‚
